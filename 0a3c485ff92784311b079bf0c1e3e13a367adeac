---
date: '2025-12-18'
deciders:
- User
- Claude
id: 20251218-local-embedding-model-with-sentence-transformers
linked_commits:
- df0af93
status: accepted
tags:
- memory
- ai
- embeddings
title: Local Embedding Model with sentence-transformers
---

# Local Embedding Model

## Status
Accepted

## Context
Semantic search requires text embeddings. Options:
- Cloud APIs (OpenAI, Cohere, Voyage)
- Local models (sentence-transformers, Ollama)

## Decision
Use local embedding generation via sentence-transformers, defaulting to all-MiniLM-L6-v2 (384 dimensions).

## Rationale
- Privacy: No project data leaves the machine
- Offline capable: Works without internet
- Free: No API costs
- Fast enough: ~50ms per embedding on CPU
- Quality: Sufficient for our semantic similarity needs

## Consequences

### Positive
- First run downloads ~90MB model
- 384-dimension embeddings (balance of quality/size)
- Model cached in .cs-memory/models/
- Can be configured to use different model

## Alternatives Considered
1. **OpenAI text-embedding-3-small**: Higher quality but API cost, privacy concerns
2. **Ollama with embedding model**: Local, flexible but heavier setup, slower
3. **Larger local models (e5-large, bge-large)**: Better quality but slower, more memory
